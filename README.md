### 系统架构

tgdb 的系统架构如下图所示，整体由两大核心模块组成：

- 计算节点：负责事务调度、图操作和查询执行，包含一个读写节点与多个只读节点。
- 存储节点：负责数据的持久化存储与管理，包含多个当前数据节点与一个历史数据节点。当前数据节点维护时态图的最新版本，而历史数据节点用于存储完整的历史版本。

![`docs/tgdb.pdf`](./docs/tgdb.jpg)

### 计算层实现

计算层是 tgdb 的核心执行框架，负责事务调度、图操作及查询执行。该层由一个读写节点与多个只读节点组成，两类节点均在 Memgraph 框架基础上扩展。

#### 读写节点

读写节点负责处理所有图更新与非时态查询操作。其实现基于 Memgraph 的查询执行框架。核心组件包括：

- 解析器&优化器与查询执行器：继承自 Memgraph 的原生查询处理框架，负责解析 Cypher 查询语句并生成物理执行计划。
- 当前态数据缓冲区：复用 Memgraph 的内存型存储引擎以维护最新版本数据，并融合时态数据布局机制。系统将 Memgraph 的核心结构映射至时态图模型：`Vertex` 表示顶点对象，`EdgeRef` 表示边对象，`Delta` 用于记录未回收的历史版本。每个结构均附加时间戳字段以标识版本生命周期，从而支持版本可追踪与时态一致性维护。缓冲区采用 LRU 策略进行替换管理，确保在内存受限条件下维持热点数据访问效率。
- 日志线程：引入重做日志机制，用于记录事务执行过程中的变更操作。日志在事务提交阶段被打包并下放至存储层，以实现持久化与版本回放。
- 通信线程：负责与存储层之间的异步交互，比如日志下放和事务提交确认。该线程周期性广播事务状态表（TST）至只读节点，用于后续只读节点的异步预取机制。

#### 只读节点

只读节点负责处理所有时态与非时态只读查询任务，并可通过水平扩展以分担复杂时态图计算负载。其内部实现继承了 Memgraph 的查询执行框架，并集成时态处理机制。主要组件包括：

- 时态解析器&优化器：在 Memgraph 原生解析与优化框架上扩展，以支持时态查询语言语义。具体而言，在 Cypher 语法文件中引入时间限定符，使用户能够在查询中直接指定时间点或时间区间的过滤条件；同时增强语法访问器逻辑，以识别并转换包含时态约束的查询语句，生成具有时态语义的抽象语法树。
- 时态查询执行器：在 Memgraph 的执行引擎上集成时态算子模型与两阶段数据拉取机制，以支持时态语义的算子级执行。对核心算子 Scan 与 Expand 进行了扩展：在 `ScanAllCursor.Pull()` 中加入 `AddHistoricalVertices()` 以捕获未回收与已回收的历史顶点版本；在 `ExpandCursor.Pull()` 中引入 `AddHistoricalEdges()` 用于检索并重构历史边及其邻接顶点。通过在执行阶段融入两阶段拉取策略，系统能够在保证一致性的前提下高效访问分布式时态数据。
- 数据缓冲区：包含当前态数据缓冲区与历史态数据缓冲区。当前态数据缓冲区与读写节点的缓冲区设计一致；历史数据缓冲区专为时态查询优化设计，通过引入两类数据结构：`HistoricalVertex` 与 `HistoricalEdge`，缓存从历史数据节点加载的历史节点和历史边版本。
- 通信线程：与读写节点类似。此外，只读节点通过接收读写节点广播的事务状态表 TST，基于 AeonGC 的异步预取机制对本地缓冲区中的相关数据项进行及时更新。

### 存储层实现

存储层负责时态数据的持久化、复制与分层归档，支持高可用与低成本的长周期数据存储。该层由当前数据节点与历史数据节点构成，均基于 RocksDB 实例实现。

#### 当前数据节点

当前数据节点负责存储当前态数据。为确保低延迟与高吞吐的访问性能，这些节点部署于高性能 SSD 存储介质上，并与计算层节点处于同一局域网络中，以降低远程通信开销。其核心组件包括：

- 日志重放线程：持续从读写节点异步接收重做日志并写入本地日志队列。线程按序解析日志记录，将操作映射至对应的数据分片，实现数据的持久化。
- 当前数据分片：采用基于哈希的分片策略对图数据进行水平划分。每个分片通过 Raft 协议维持副本一致性，以实现多节点间的数据复制与容错。
- 通信线程：负责将日志重放过程中生成的历史数据异步传输至历史数据节点。

#### 历史数据节点

历史数据节点负责存储系统的历史版本数据。系统仅部署单一历史节点，其底层存储基于 RocksDB 实例构建，而 RocksDB 的文件系统通过 CatFS 挂载远端云对象存储（如 AWS S3）。其核心组件包含：

- 通信线程：持续从各当前数据节点接收历史数据，并将其写入本地版本队列中等待处理。
- 数据迁移线程：负责从版本队列中提取待归档的历史版本数据，按照 AeonG 提出的“锚点 + 增量”的数据组织模型进行重构。重组后的版本数据以压缩的键值对形式写入本地 RocksDB 实例中。
- 历史数据与云对象存储：历史数据存储至 RocksDB 实例。RocksDB 通过 CatFS 将远端云对象存储直接挂载至本地文件系统，依托 CatFS 的缓存与增量同步机制，实现 RocksDB 文件在本地与云端之间的无缝映射，使 RocksDB 能以原生 POSIX 文件系统语义访问 COS 对象，从而在无需修改 RocksDB 源码的前提下，实现本地高速访问与云端持久化的统一。

